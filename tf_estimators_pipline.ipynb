{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "60k_text_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "34egWrGY3-QX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ysNVmVp_NhNs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tf.enable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkV1N_oh4joS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile as z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qfx3tBXroVk3",
        "colab_type": "code",
        "outputId": "857c1d83-527d-4956-a9bc-c5bd14bcc854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "MOUNT_POINT_DRIVE = '/content/gdrive'\n",
        "drive.mount(MOUNT_POINT_DRIVE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k7YY6Kmz6Tpg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_DATA = '/content/gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MEBgrycC4HTK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = z.ZipFile(PATH_TO_DATA + 'train.csv.zip').extract('train.csv'), z.ZipFile(PATH_TO_DATA + 'test.csv.zip').extract('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vxvucn7G43ex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = pd.read_csv(train), pd.read_csv(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XP_hKd1G6QxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus, target = train['text'], train['labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hxaw6k5NI7jB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if -1 in target.unique():\n",
        "  sub = target.unique().shape[0]\n",
        "  target = target.transform(lambda x:x + sub if x==-1 else x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oaHzhDpd29bm",
        "colab_type": "code",
        "outputId": "a039d2b4-6f6e-4d71-db21-1610ca16e560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8HtPha9Pyksc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def transform(corpus):\n",
        "  pattern = re.compile(r'[^A-Za-z ]')  \n",
        "  corpus = corpus.apply(lambda x: x.lower())\n",
        "  corpus = corpus.apply(lambda x: re.sub(pattern, ' ', x))\n",
        "  \n",
        "  corpus = corpus.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
        "  \n",
        "  lemmatizer = nltk.WordNetLemmatizer()\n",
        "  corpus = corpus.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "  \n",
        "  return corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4rxbaHLI1xFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = transform(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "COyQtYMN48-w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "for line in corpus:\n",
        "  for word in line.split():\n",
        "    if word not in d:\n",
        "      d[word]=1\n",
        "    else:\n",
        "      d[word]+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vy7HaEQqCDID",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pad_index=0\n",
        "start_index=1\n",
        "out_index=2\n",
        "shuffle_index=1\n",
        "\n",
        "def index_corpus(corpus):\n",
        "  corpus_embeded = []\n",
        "\n",
        "  for line in corpus:\n",
        "    line_embeded = [1]\n",
        "    for word in line.split():\n",
        "      line_embeded.append(d[word]+shuffle_index if word in d and d[word]>1  else 2)\n",
        "    corpus_embeded.append(line_embeded)\n",
        "  return corpus_embeded\n",
        "\n",
        "corpus_embeded = index_corpus(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dLgSU0WPEZ7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lens = []\n",
        "\n",
        "for line in corpus_embeded:\n",
        "  lens.append(len(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfRTJaOfEkda",
        "colab_type": "code",
        "outputId": "350c3a15-6345-45d9-884a-49bdeba8302d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.hist(lens);"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJIKZQBIUqEMAEkqlAEgSYUyACSpUP8PzF0O0wWrPUgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "L6OsvFc8Ept_",
        "colab_type": "code",
        "outputId": "0d7fd606-32df-4010-ff1a-f2ed1c99ccd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "sentence_size = 15\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "corpus_embeded = pad_sequences(corpus_embeded, maxlen = sentence_size, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3dzk2Mvq8N8S",
        "colab_type": "code",
        "outputId": "3d10a580-786b-40d9-b73d-f0d55e8282ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "corpus_embeded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150832, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "NuuEbc-ewT_B",
        "colab_type": "code",
        "outputId": "f9d7e441-ae37-4c81-b81b-492744bf615a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "cell_type": "code",
      "source": [
        "corpus_embeded[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   1,   74,   17,  236,   42,  248,   42,   15,  713,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [   1,   48,   17,  236,  248,    8,   17,  713,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [   1, 4572,    4,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [   1,  525,    4,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [   1,  804, 1802,  507,  145,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "UbsqupLjwY7P",
        "colab_type": "code",
        "outputId": "54e65f6b-bf40-456a-dae1-e5fe77154da8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "target[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    1\n",
              "3    1\n",
              "4    2\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "chJed0Kl-GBJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сейчас буду писать функцию для импута в трейне"
      ]
    },
    {
      "metadata": {
        "id": "D6jJ1ReSA9JJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_input_fn(x_train, labels, params, training=False):\n",
        "  data = tf.data.Dataset.from_tensor_slices(({\n",
        "            'sentences': x_train}\n",
        "                                             \n",
        "            , labels))\n",
        "  \n",
        "  if training:\n",
        "    data = data.shuffle(buffer_size=params['buffer_size'])\n",
        "    data = data.repeat(params['num_of_epochs'])\n",
        "    \n",
        "  data = data.batch(params['batch_size'], drop_remainder=True)\n",
        "  iterator = data.make_one_shot_iterator()\n",
        "  batch_feat, batch_lab = iterator.get_next()\n",
        "  \n",
        "  return batch_feat, batch_lab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NIFFwFIdvsic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Здесь пишу функцию для модели"
      ]
    },
    {
      "metadata": {
        "id": "dNLZ-KZBrqYc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_model_fn(features, labels, mode, params):\n",
        "  input_layer = tf.contrib.layers.embed_sequence(features['sentences'],\n",
        "                                                 vocab_size= params['vocab_size'],\n",
        "                                                 embed_dim = params['embed_size'],\n",
        "                                                 initializer = params['embed_init'])\n",
        "  \n",
        "  rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(64)\n",
        "  \n",
        "  _, final_state = tf.nn.dynamic_rnn(rnn_cell, input_layer, sequence_length=[sentence_size]*params['batch_size'], dtype=tf.float32)\n",
        "  \n",
        "  logits = tf.layers.dense(final_state.h, units=params['num_of_classes'])\n",
        "  \n",
        "  predictions = {'class_id':tf.argmax(logits, axis=1)}\n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            predictions=predictions\n",
        "    )\n",
        "  \n",
        "  \n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "  \n",
        "  accuracy = tf.metrics.accuracy(labels, predictions['class_id'])\n",
        "\n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(\n",
        "             mode,\n",
        "             loss = loss,\n",
        "             train_op = train_op\n",
        "    )\n",
        "  \n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode,\n",
        "        loss = loss,\n",
        "        eval_metric_ops = {'accuracy': accuracy}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RqplPnJovLEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сделать классификатор"
      ]
    },
    {
      "metadata": {
        "id": "C_7KY-sYAJ3n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def set_new_session():\n",
        "  sess = tf.get_default_session()\n",
        "  if sess is not None:\n",
        "    sess.close()\n",
        "  tf.reset_default_graph()\n",
        "  config = tf.ConfigProto()\n",
        "  s = tf.InteractiveSession(config=config)\n",
        "  return s\n",
        "\n",
        "s = set_new_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WjQaDchY_yY0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = corpus_embeded, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_ABpzu6_7ds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert x_train.shape[0]==y_train.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uMqY5PpxqjLY",
        "colab_type": "code",
        "outputId": "74a89a64-90cf-42a3-a72c-b1fe7f65d2fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "import operator\n",
        "def get_vocab_size(d, threshold):\n",
        "  sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
        "  d = dict(sorted_d)\n",
        "  for elem, index in zip(d.items(), range(len(d))):\n",
        "    if elem[1]==threshold:\n",
        "      vocab_size = index\n",
        "      break\n",
        "  return vocab_size\n",
        "\n",
        "threshold = 1\n",
        "vocab_size = get_vocab_size(d, threshold)\n",
        "print('vocab_size: ', vocab_size)\n",
        "embed_size=50\n",
        "embed_init = tf.random_normal_initializer()\n",
        "num_of_classes = y_train.unique().shape[0]\n",
        "batch_size=100"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size:  21294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fe5ocV3vxK9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {'vocab_size':vocab_size, 'embed_size':embed_size, 'embed_init': embed_init, 'num_of_classes': num_of_classes, 'batch_size':batch_size}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R9bbTKyMvO2-",
        "colab_type": "code",
        "outputId": "47c98c43-fde2-45cc-d7f9-2850f78c3063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "classifier  = tf.estimator.Estimator(model_fn = my_model_fn, model_dir = '/content/gdrive/My Drive/Colab Notebooks/60k text classification', params = params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/My Drive/Colab Notebooks/60k text classification', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7efffa59b438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b85z7tnwwBef",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train"
      ]
    },
    {
      "metadata": {
        "id": "LCSxWawtzClS",
        "colab_type": "code",
        "outputId": "116ee4e4-3ce4-47fa-eafa-aa7bcd78b790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2992
        }
      },
      "cell_type": "code",
      "source": [
        "params_for_input = {'buffer_size':x_train.shape[0], 'num_of_epochs':5, 'batch_size':batch_size}\n",
        "classifier.train(input_fn = lambda: my_input_fn(x_train, y_train, params_for_input, training=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt-9199\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 9199 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt.\n",
            "INFO:tensorflow:loss = 9.2030325, step = 9199\n",
            "INFO:tensorflow:global_step/sec: 36.7479\n",
            "INFO:tensorflow:loss = 8.163788, step = 9299 (2.728 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.461\n",
            "INFO:tensorflow:loss = 8.236622, step = 9399 (2.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.3657\n",
            "INFO:tensorflow:loss = 8.121407, step = 9499 (2.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.896\n",
            "INFO:tensorflow:loss = 7.7486706, step = 9599 (2.508 sec)\n",
            "INFO:tensorflow:global_step/sec: 37.1587\n",
            "INFO:tensorflow:loss = 8.609973, step = 9699 (2.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.4599\n",
            "INFO:tensorflow:loss = 8.0480385, step = 9799 (2.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.8\n",
            "INFO:tensorflow:loss = 8.376955, step = 9899 (2.449 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.4339\n",
            "INFO:tensorflow:loss = 8.4479, step = 9999 (2.476 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.0264\n",
            "INFO:tensorflow:loss = 8.290016, step = 10099 (2.438 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.1678\n",
            "INFO:tensorflow:loss = 8.3321, step = 10199 (2.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.623\n",
            "INFO:tensorflow:loss = 8.355856, step = 10299 (2.405 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.4285\n",
            "INFO:tensorflow:loss = 7.8772283, step = 10399 (2.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.9605\n",
            "INFO:tensorflow:loss = 8.495925, step = 10499 (2.444 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.9583\n",
            "INFO:tensorflow:loss = 7.423401, step = 10599 (2.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 40.7777\n",
            "INFO:tensorflow:loss = 8.44504, step = 10699 (2.452 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.5112\n",
            "INFO:tensorflow:loss = 8.158548, step = 10799 (2.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.4417\n",
            "INFO:tensorflow:loss = 8.494707, step = 10899 (2.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.2197\n",
            "INFO:tensorflow:loss = 8.233197, step = 10999 (2.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.6122\n",
            "INFO:tensorflow:loss = 7.5759363, step = 11099 (2.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.3714\n",
            "INFO:tensorflow:loss = 8.113468, step = 11199 (2.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.2677\n",
            "INFO:tensorflow:loss = 8.234006, step = 11299 (2.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.651\n",
            "INFO:tensorflow:loss = 8.140279, step = 11399 (2.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9586\n",
            "INFO:tensorflow:loss = 7.725468, step = 11499 (2.386 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9882\n",
            "INFO:tensorflow:loss = 7.3497353, step = 11599 (2.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9412\n",
            "INFO:tensorflow:loss = 7.97869, step = 11699 (2.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8331\n",
            "INFO:tensorflow:loss = 8.336203, step = 11799 (2.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.5569\n",
            "INFO:tensorflow:loss = 7.7955036, step = 11899 (2.411 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.1602\n",
            "INFO:tensorflow:loss = 8.059278, step = 11999 (2.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0639\n",
            "INFO:tensorflow:loss = 8.401998, step = 12099 (2.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.2773\n",
            "INFO:tensorflow:loss = 8.041919, step = 12199 (2.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0163\n",
            "INFO:tensorflow:loss = 8.115813, step = 12299 (2.381 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.7052\n",
            "INFO:tensorflow:loss = 8.171986, step = 12399 (2.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.3884\n",
            "INFO:tensorflow:loss = 8.10321, step = 12499 (2.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8205\n",
            "INFO:tensorflow:loss = 8.022385, step = 12599 (2.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9145\n",
            "INFO:tensorflow:loss = 7.517914, step = 12699 (2.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.279\n",
            "INFO:tensorflow:loss = 7.910004, step = 12799 (2.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.179\n",
            "INFO:tensorflow:loss = 7.824084, step = 12899 (2.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.2721\n",
            "INFO:tensorflow:loss = 7.332376, step = 12999 (2.367 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9444\n",
            "INFO:tensorflow:loss = 6.983019, step = 13099 (2.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0667\n",
            "INFO:tensorflow:loss = 8.427336, step = 13199 (2.373 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.1356\n",
            "INFO:tensorflow:loss = 8.29421, step = 13299 (2.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0428\n",
            "INFO:tensorflow:loss = 8.2176285, step = 13399 (2.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.025\n",
            "INFO:tensorflow:loss = 7.962226, step = 13499 (2.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0774\n",
            "INFO:tensorflow:loss = 8.352442, step = 13599 (2.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8904\n",
            "INFO:tensorflow:loss = 7.7297654, step = 13699 (2.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0596\n",
            "INFO:tensorflow:loss = 8.195449, step = 13799 (2.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.033\n",
            "INFO:tensorflow:loss = 7.330019, step = 13899 (2.375 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.443\n",
            "INFO:tensorflow:loss = 7.271534, step = 13999 (2.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8411\n",
            "INFO:tensorflow:loss = 7.929907, step = 14099 (2.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.5349\n",
            "INFO:tensorflow:loss = 7.1713905, step = 14199 (2.350 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9817\n",
            "INFO:tensorflow:loss = 7.335063, step = 14299 (2.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.7889\n",
            "INFO:tensorflow:loss = 7.7569704, step = 14399 (2.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.4167\n",
            "INFO:tensorflow:loss = 7.5775743, step = 14499 (2.353 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.3484\n",
            "INFO:tensorflow:loss = 7.1730056, step = 14599 (2.366 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.3357\n",
            "INFO:tensorflow:loss = 7.601362, step = 14699 (2.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0082\n",
            "INFO:tensorflow:loss = 7.472841, step = 14799 (2.379 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9539\n",
            "INFO:tensorflow:loss = 7.7025056, step = 14899 (2.384 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.6294\n",
            "INFO:tensorflow:loss = 8.008509, step = 14999 (2.399 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9257\n",
            "INFO:tensorflow:loss = 7.883578, step = 15099 (2.387 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9942\n",
            "INFO:tensorflow:loss = 7.3546214, step = 15199 (2.382 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.9713\n",
            "INFO:tensorflow:loss = 6.53508, step = 15299 (2.378 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.1809\n",
            "INFO:tensorflow:loss = 6.8368144, step = 15399 (2.369 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.4385\n",
            "INFO:tensorflow:loss = 7.0320654, step = 15499 (2.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.6306\n",
            "INFO:tensorflow:loss = 7.2298427, step = 15599 (2.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.5022\n",
            "INFO:tensorflow:loss = 6.9433093, step = 15699 (2.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8626\n",
            "INFO:tensorflow:loss = 7.694779, step = 15799 (2.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0334\n",
            "INFO:tensorflow:loss = 7.009547, step = 15899 (2.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.1338\n",
            "INFO:tensorflow:loss = 7.7677917, step = 15999 (2.374 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.4072\n",
            "INFO:tensorflow:loss = 7.29997, step = 16099 (2.358 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.0294\n",
            "INFO:tensorflow:loss = 7.100752, step = 16199 (2.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.7649\n",
            "INFO:tensorflow:loss = 7.265717, step = 16299 (2.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.3342\n",
            "INFO:tensorflow:loss = 7.153479, step = 16399 (2.360 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.6461\n",
            "INFO:tensorflow:loss = 7.2341, step = 16499 (2.345 sec)\n",
            "INFO:tensorflow:global_step/sec: 41.8341\n",
            "INFO:tensorflow:loss = 7.086872, step = 16599 (2.394 sec)\n",
            "INFO:tensorflow:global_step/sec: 42.4302\n",
            "INFO:tensorflow:loss = 6.49605, step = 16699 (2.353 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 16740 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 7.2140613.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7efffa59b0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "rUD5ep8tN-EE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Eval"
      ]
    },
    {
      "metadata": {
        "id": "jpzYwmHKtV2X",
        "colab_type": "code",
        "outputId": "2eb5205c-1676-4997-8a01-f9812a76d3f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "params_for_input_eval = {'buffer_size':x_train.shape[0], 'num_of_epochs':1, 'batch_size':batch_size}\n",
        "eval_res = classifier.evaluate(input_fn = lambda: my_input_fn(x_train, y_train, params_for_input_eval, training=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-21T17:55:25Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt-16740\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-21-17:56:01\n",
            "INFO:tensorflow:Saving dict for global step 16740: accuracy = 0.1991313, global_step = 16740, loss = 6.67159\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 16740: /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt-16740\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PepD0-UOR9gr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict"
      ]
    },
    {
      "metadata": {
        "id": "xJHVTVQyPnDD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_corpus = test['text']\n",
        "test_corpus = transform(test_corpus)\n",
        "\n",
        "test_corpus_embeded = index_corpus(test_corpus)\n",
        "\n",
        "test_corpus_embeded = pad_sequences(test_corpus_embeded, maxlen = sentence_size, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQ0hrdNbbj1i",
        "colab_type": "code",
        "outputId": "2010140c-811a-4512-d47b-5111ce1e8f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "test_corpus_embeded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58788, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "CA9X1QCoS2KZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_input_fn(x_test):\n",
        "  data = tf.data.Dataset.from_tensor_slices(({\n",
        "            'sentences': x_test}))\n",
        "    \n",
        "  data = data.repeat(1)\n",
        "  data = data.batch(batch_size)\n",
        "  iterator = data.make_one_shot_iterator()\n",
        "  batch = iterator.get_next()\n",
        "  return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8FP-P6kbtPS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_swallen = np.concatenate((test_corpus_embeded, np.zeros(shape=(12, 15), dtype=np.int32)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V70DafjGcKLu",
        "colab_type": "code",
        "outputId": "fcfb93d8-f66a-4c83-f082-8c38479d1892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "test_swallen.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58800, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "2mso1lnfUOd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = classifier.predict(input_fn = lambda: predict_input_fn(test_swallen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSalNQc8WUK9",
        "colab_type": "code",
        "outputId": "bef5cf68-9a14-4138-a8ee-3aff350c605d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for elem in predictions:\n",
        "  results.append(elem['class_id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/model.ckpt-16740\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bR7xPdsNi9Qt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = results[:-12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4e9bKE3QjCYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert len(results)==test_corpus_embeded.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I0cER-ofWVzc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! touch '/content/submision.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJKbXRbndqWd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/submision.csv', 'w') as file:\n",
        "  file.write('index' +',' + 'labels' + '\\n')\n",
        "  for index, label in zip(range(len(results)), results):\n",
        "    file.write(str(index) + ',' + str(label) + '\\n' if label!= 60416 else str(index) + ',' + str(-1) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2jbRayM-hSuC",
        "colab_type": "code",
        "outputId": "fc11177a-5ff0-4216-9649-3137c6823aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "! KAGGLE_USERNAME='nikitamartynov' KAGGLE_KEY='3fabe7b3f96f3f0b04b23fd757efb93c' kaggle competitions submit -c 60k-classes-text-classification -f submision.csv -m \"pls, do not judge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 506k/506k [00:11<00:00, 46.2kB/s]\n",
            "Successfully submitted to 60k Classes Text Classification"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kiZNHJEYvz7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сделать на нормальных эмбедингах"
      ]
    },
    {
      "metadata": {
        "id": "IfzLR9Pyz9rU",
        "colab_type": "code",
        "outputId": "4c8d0e4b-4c3e-4e14-f3bb-db6895b8a613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "! mkdir '/content/gdrive/My Drive/Embeddings'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/gdrive/My Drive/Embeddings’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OJlzL1w60Uoi",
        "colab_type": "code",
        "outputId": "a8800ec1-c082-4dc2-f689-0130389b022e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "! wget -P '/content/gdrive/My Drive/Embeddings' 'http://nlp.stanford.edu/data/glove.6B.zip'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-22 09:57:06--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-03-22 09:57:07--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘/content/gdrive/My Drive/Embeddings/glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.43MB/s    in 2m 18s  \n",
            "\n",
            "2019-03-22 09:59:25 (5.96 MB/s) - ‘/content/gdrive/My Drive/Embeddings/glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OnuHFMPK1OPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_size = 300\n",
        "\n",
        "EMBEDDINGS_FILE = 'glove.6B.' + str(embeddings_size) + 'd.txt'\n",
        "\n",
        "embeddings = z.ZipFile('/content/gdrive/My Drive/Embeddings/glove.6B.zip').extract(EMBEDDINGS_FILE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m9MU1bDC28nU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "e = {}\n",
        "with open(embeddings) as file:\n",
        "  for line in file:\n",
        "    s = line.split()\n",
        "    word = s[0]\n",
        "    vector = np.asarray(list(map(np.float, s[1:])), dtype=np.float32)\n",
        "    \n",
        "    assert vector.shape[0]==embeddings_size\n",
        "    \n",
        "    e[word] = vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_0u6nrGLZJV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Перекодирую предложения"
      ]
    },
    {
      "metadata": {
        "id": "RgOJ2xCgLTzT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n",
        "d_s = dict(sorted_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-QPM_FSLmZN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for elem, index in zip(d_s.items(), range(len(d_s))):\n",
        "  d_s[elem[0]] = index + 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tV1O1UphMDWv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reindex_corpus(corpus):\n",
        "  corpus_embeded = []\n",
        "  \n",
        "  for line in corpus:\n",
        "    line_embeded = [1]\n",
        "    for word in line.split():\n",
        "      line_embeded.append(d_s[word] if word in d_s else out_index)\n",
        "    corpus_embeded.append(line_embeded)\n",
        "    \n",
        "  return corpus_embeded\n",
        "\n",
        "\n",
        "corpus_reembeded = reindex_corpus(corpus)\n",
        "  \n",
        "corpus_reembeded = pad_sequences(corpus_reembeded, maxlen = sentence_size, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxlfcqQyQlAQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Сделаю матрицу новых эмбедингов"
      ]
    },
    {
      "metadata": {
        "id": "hNcHODnvQZ6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = get_vocab_size(d, threshold)\n",
        "\n",
        "embeddings_matrix = np.random.normal(size=(vocab_size + 3, embeddings_size))\n",
        "\n",
        "for word, index in d_s.items():\n",
        "  if index <=vocab_size and word in e:\n",
        "    embeddings_matrix[index] = e[word]\n",
        "    \n",
        "embeddings_matrix = np.asarray(embeddings_matrix, dtype=np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_jvPWufW0sP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assert embeddings_matrix.shape == (vocab_size + 3, embeddings_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bALz8EdNX6oS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Инициализатор"
      ]
    },
    {
      "metadata": {
        "id": "9VEfF6KYXvCE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_initializer(shape=None, dtype=tf.float32, partition_info=None):\n",
        "    assert dtype is tf.float32\n",
        "    return embeddings_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-5zZN0_yZJrc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Модель та же"
      ]
    },
    {
      "metadata": {
        "id": "wz_oFQdGZ7Cp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = corpus_reembeded, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9hBdFZjZkzY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_of_classes = y_train.unique().shape[0]\n",
        "batch_size=100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XaB0VTc1ZHjr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "params = {'vocab_size':vocab_size, 'embed_size':embeddings_size, 'embed_init': my_initializer, 'num_of_classes': num_of_classes, 'batch_size':batch_size}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VxxVPxBJaSNY",
        "colab_type": "code",
        "outputId": "a238a018-064f-4bc5-b6f8-fbb3fb648140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "classifier_pretrained  = tf.estimator.Estimator(model_fn = my_model_fn, model_dir = '/content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_', params = params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8df8fda5f8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s6oVDBrva3OG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train"
      ]
    },
    {
      "metadata": {
        "id": "gAOETOUyYCPf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s = set_new_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IPn2hJBax6X",
        "colab_type": "code",
        "outputId": "3ff891f2-7183-4807-cf7a-2ca8966c9ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "cell_type": "code",
      "source": [
        "params_for_input = {'buffer_size':x_train.shape[0], 'num_of_epochs':1, 'batch_size':batch_size}\n",
        "classifier_pretrained.train(input_fn = lambda: my_input_fn(x_train, y_train, params_for_input, training=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt-9049\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 9049 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt.\n",
            "INFO:tensorflow:loss = 8.712929, step = 9049\n",
            "INFO:tensorflow:global_step/sec: 34.9171\n",
            "INFO:tensorflow:loss = 9.092016, step = 9149 (2.866 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.153\n",
            "INFO:tensorflow:loss = 9.527919, step = 9249 (2.554 sec)\n",
            "INFO:tensorflow:global_step/sec: 38.7836\n",
            "INFO:tensorflow:loss = 9.663826, step = 9349 (2.583 sec)\n",
            "INFO:tensorflow:global_step/sec: 30.5234\n",
            "INFO:tensorflow:loss = 9.610166, step = 9449 (3.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 38.7937\n",
            "INFO:tensorflow:loss = 8.979104, step = 9549 (2.574 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.1496\n",
            "INFO:tensorflow:loss = 9.636356, step = 9649 (2.558 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.0947\n",
            "INFO:tensorflow:loss = 9.66057, step = 9749 (2.555 sec)\n",
            "INFO:tensorflow:global_step/sec: 38.8152\n",
            "INFO:tensorflow:loss = 9.212426, step = 9849 (2.576 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.0739\n",
            "INFO:tensorflow:loss = 8.836021, step = 9949 (2.562 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.2583\n",
            "INFO:tensorflow:loss = 8.727394, step = 10049 (2.545 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.0294\n",
            "INFO:tensorflow:loss = 8.834915, step = 10149 (2.566 sec)\n",
            "INFO:tensorflow:global_step/sec: 38.8886\n",
            "INFO:tensorflow:loss = 8.373912, step = 10249 (2.570 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.2012\n",
            "INFO:tensorflow:loss = 8.970872, step = 10349 (2.548 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.6857\n",
            "INFO:tensorflow:loss = 9.318406, step = 10449 (2.522 sec)\n",
            "INFO:tensorflow:global_step/sec: 39.1027\n",
            "INFO:tensorflow:loss = 8.58901, step = 10549 (2.558 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 10557 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 9.29476.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f8df8fdac88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "metadata": {
        "id": "akta66_Sespc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ]
    },
    {
      "metadata": {
        "id": "kl38cWJbbxvh",
        "colab_type": "code",
        "outputId": "d0089410-cb31-42b6-a71c-af36f5bb2250",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "params_for_input_eval = {'buffer_size':x_train.shape[0], 'num_of_epochs':1, 'batch_size':batch_size}\n",
        "eval_res = classifier_pretrained.evaluate(input_fn = lambda: my_input_fn(x_train, y_train, params_for_input_eval, training=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-03-24T16:17:44Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt-9049\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-03-24-16:18:21\n",
            "INFO:tensorflow:Saving dict for global step 9049: accuracy = 0.19995359, global_step = 9049, loss = 9.155079\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9049: /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt-9049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "c6XTufagfDzo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict"
      ]
    },
    {
      "metadata": {
        "id": "zMkV0wd-fAxr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_corpus = test['text']\n",
        "test_corpus = transform(test_corpus)\n",
        "\n",
        "test_corpus_embeded = reindex_corpus(test_corpus)\n",
        "\n",
        "test_corpus_embeded = pad_sequences(test_corpus_embeded, maxlen = sentence_size, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a-WEQRtWfnZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_swallen = np.concatenate((test_corpus_embeded, np.zeros(shape=(12, 15), dtype=np.int32)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6hSUNnwyf9kP",
        "colab_type": "code",
        "outputId": "a7fdbb05-bebb-4740-e4fb-44d8e11c63a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "test_swallen.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58800, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "metadata": {
        "id": "80x75btdf-9N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = classifier_pretrained.predict(input_fn = lambda: predict_input_fn(test_swallen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZhdJIBdgMzi",
        "colab_type": "code",
        "outputId": "07b6c27e-84ff-47dc-ee24-7f1d1eec7f0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for elem in predictions:\n",
        "  results.append(elem['class_id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/pretrained_/model.ckpt-10557\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nQ5YQDdtgUCT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = results[:-12]\n",
        "\n",
        "assert len(results)==test_corpus_embeded.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "stq-6xVZgcoN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! touch '/content/submission.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XKu60pBBgjJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/submission.csv', 'w') as file:\n",
        "  file.write('index' +',' + 'labels' + '\\n')\n",
        "  for index, label in zip(range(len(results)), results):\n",
        "    file.write(str(index) + ',' + str(label) + '\\n' if label!= 60416 else str(index) + ',' + str(-1) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRGpe0rAgzxx",
        "colab_type": "code",
        "outputId": "5ee1dc6a-9327-4284-816b-349dc8e16a76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "! KAGGLE_USERNAME='nikitamartynov' KAGGLE_KEY='3fabe7b3f96f3f0b04b23fd757efb93c' kaggle competitions submit -c 60k-classes-text-classification -f submission.csv -m \"pls, do not judge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 508k/508k [00:00<00:00, 1.65MB/s]\n",
            "Successfully submitted to 60k Classes Text Classification"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Slym_TTih_S6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Не сработало"
      ]
    },
    {
      "metadata": {
        "id": "0Cl74xdPVnja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try convs + rnn"
      ]
    },
    {
      "metadata": {
        "id": "id-E3rmIU01F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_model_fn_cnn(features, labels, mode, params):\n",
        "  input_layer = tf.contrib.layers.embed_sequence(features['sentences'],\n",
        "                                                 vocab_size= params['vocab_size'],\n",
        "                                                 embed_dim = params['embed_size'],\n",
        "                                                 initializer = params['embed_init'])\n",
        "  \n",
        "  conv1 = tf.layers.conv1d(inputs=input_layer,\n",
        "                      filters=128,\n",
        "                       kernel_size=5,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv2 = tf.layers.conv1d(inputs=conv1,\n",
        "                      filters=256,\n",
        "                       kernel_size=5,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv3 = tf.layers.conv1d(inputs=conv2,\n",
        "                      filters=256,\n",
        "                       kernel_size=4,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv4 = tf.layers.conv1d(inputs=conv3,\n",
        "                      filters=512,\n",
        "                       kernel_size=4,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv5 = tf.layers.conv1d(inputs=conv4,\n",
        "                      filters=768,\n",
        "                       kernel_size=3,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv6 = tf.layers.conv1d(inputs=conv5,\n",
        "                      filters=1024,\n",
        "                       kernel_size=3,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv7 = tf.layers.conv1d(inputs=conv6,\n",
        "                      filters=2048,\n",
        "                       kernel_size=3,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  conv8 = tf.layers.conv1d(inputs=conv7,\n",
        "                      filters=4096,\n",
        "                       kernel_size=3,\n",
        "                      padding='same',\n",
        "                      activation=tf.nn.relu)\n",
        "  \n",
        "  rnn_cell = tf.nn.rnn_cell.BasicLSTMCell(64)\n",
        "  \n",
        "  _, final_state = tf.nn.dynamic_rnn(rnn_cell, conv8, sequence_length = [sentence_size]*params['batch_size'], dtype=tf.float32)\n",
        "                             \n",
        "    \n",
        "  dense1 = tf.layers.dense(final_state.h, units=1000, activation=tf.nn.relu)\n",
        "  \n",
        "  logits = tf.layers.dense(dense1, units=params['num_of_classes'])\n",
        "  \n",
        "  predictions = {'class_id':tf.argmax(logits, axis=1)}\n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.PREDICT:\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "            mode,\n",
        "            predictions=predictions\n",
        "    )\n",
        "  \n",
        "  \n",
        "  loss = tf.losses.sparse_softmax_cross_entropy(labels, logits)\n",
        "  \n",
        "  accuracy = tf.metrics.accuracy(labels, predictions['class_id'])\n",
        "\n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.TRAIN:\n",
        "    optimizer = tf.train.AdamOptimizer()\n",
        "    train_op = optimizer.minimize(loss, global_step = tf.train.get_global_step())\n",
        "    \n",
        "    return tf.estimator.EstimatorSpec(\n",
        "             mode,\n",
        "             loss = loss,\n",
        "             train_op = train_op\n",
        "    )\n",
        "  \n",
        "  \n",
        "  if mode==tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode,\n",
        "        loss = loss,\n",
        "        eval_metric_ops = {'accuracy': accuracy}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXShhICQ1lIx",
        "colab_type": "code",
        "outputId": "04320a9a-0aaa-430d-8129-3046542b46a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "cell_type": "code",
      "source": [
        "params = {'vocab_size':vocab_size, 'embed_size':embed_size, 'embed_init': embed_init, 'num_of_classes': num_of_classes, 'batch_size':batch_size}\n",
        "classifier_cnn = tf.estimator.Estimator(model_fn = my_model_fn_cnn, model_dir = '/content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn', params=params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94d87c7b00>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJGaVt0l58z8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train cnn"
      ]
    },
    {
      "metadata": {
        "id": "A1dJGg7i5vDI",
        "colab_type": "code",
        "outputId": "5a644f4c-7f13-449f-8386-f8c461cf9bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3729
        }
      },
      "cell_type": "code",
      "source": [
        "params_for_input = {'buffer_size':x_train.shape[0], 'num_of_epochs':6, 'batch_size':batch_size}\n",
        "classifier_cnn.train(input_fn = lambda: my_input_fn(x_train, y_train, params_for_input, training=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From <ipython-input-121-f690e2dc7296>:55: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-121-f690e2dc7296>:57: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:loss = 11.008908, step = 0\n",
            "INFO:tensorflow:global_step/sec: 3.19218\n",
            "INFO:tensorflow:loss = 10.015626, step = 100 (31.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22239\n",
            "INFO:tensorflow:loss = 10.198894, step = 200 (31.029 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22876\n",
            "INFO:tensorflow:loss = 10.611458, step = 300 (30.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22762\n",
            "INFO:tensorflow:loss = 10.451361, step = 400 (30.984 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22611\n",
            "INFO:tensorflow:loss = 9.898746, step = 500 (30.994 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22737\n",
            "INFO:tensorflow:loss = 10.86993, step = 600 (30.987 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22819\n",
            "INFO:tensorflow:loss = 10.448767, step = 700 (30.974 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21759\n",
            "INFO:tensorflow:loss = 10.251247, step = 800 (31.084 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22321\n",
            "INFO:tensorflow:loss = 10.467633, step = 900 (31.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2238\n",
            "INFO:tensorflow:loss = 9.846108, step = 1000 (31.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22768\n",
            "INFO:tensorflow:loss = 10.468766, step = 1100 (30.983 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22223\n",
            "INFO:tensorflow:loss = 10.44996, step = 1200 (31.031 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22312\n",
            "INFO:tensorflow:loss = 10.360426, step = 1300 (31.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21917\n",
            "INFO:tensorflow:loss = 9.698093, step = 1400 (31.061 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2333\n",
            "INFO:tensorflow:loss = 10.490471, step = 1500 (30.933 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22489\n",
            "INFO:tensorflow:loss = 9.805387, step = 1600 (31.009 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23351\n",
            "INFO:tensorflow:loss = 8.585391, step = 1700 (30.926 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22595\n",
            "INFO:tensorflow:loss = 9.535771, step = 1800 (31.001 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23761\n",
            "INFO:tensorflow:loss = 9.533627, step = 1900 (30.884 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1932 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.54611\n",
            "INFO:tensorflow:loss = 9.301112, step = 2000 (39.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.224\n",
            "INFO:tensorflow:loss = 9.491441, step = 2100 (31.016 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22912\n",
            "INFO:tensorflow:loss = 9.309458, step = 2200 (30.972 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21917\n",
            "INFO:tensorflow:loss = 9.716554, step = 2300 (31.064 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22757\n",
            "INFO:tensorflow:loss = 9.5729685, step = 2400 (30.980 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22719\n",
            "INFO:tensorflow:loss = 9.738946, step = 2500 (30.986 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22669\n",
            "INFO:tensorflow:loss = 9.49016, step = 2600 (30.992 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21638\n",
            "INFO:tensorflow:loss = 9.346315, step = 2700 (31.094 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2245\n",
            "INFO:tensorflow:loss = 9.560516, step = 2800 (31.013 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21879\n",
            "INFO:tensorflow:loss = 9.615323, step = 2900 (31.063 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23112\n",
            "INFO:tensorflow:loss = 9.734705, step = 3000 (30.955 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22362\n",
            "INFO:tensorflow:loss = 9.470358, step = 3100 (31.020 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22787\n",
            "INFO:tensorflow:loss = 9.040212, step = 3200 (30.981 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22003\n",
            "INFO:tensorflow:loss = 9.450475, step = 3300 (31.051 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22835\n",
            "INFO:tensorflow:loss = 9.877218, step = 3400 (30.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22768\n",
            "INFO:tensorflow:loss = 9.303714, step = 3500 (30.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23016\n",
            "INFO:tensorflow:loss = 8.972941, step = 3600 (30.960 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21881\n",
            "INFO:tensorflow:loss = 9.607464, step = 3700 (31.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22884\n",
            "INFO:tensorflow:loss = 8.779348, step = 3800 (30.971 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3841 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.53197\n",
            "INFO:tensorflow:loss = 9.423137, step = 3900 (39.494 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23092\n",
            "INFO:tensorflow:loss = 9.333549, step = 4000 (30.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22698\n",
            "INFO:tensorflow:loss = 9.758267, step = 4100 (30.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23209\n",
            "INFO:tensorflow:loss = 9.988515, step = 4200 (30.940 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22828\n",
            "INFO:tensorflow:loss = 9.444674, step = 4300 (30.975 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22329\n",
            "INFO:tensorflow:loss = 9.273254, step = 4400 (31.027 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22708\n",
            "INFO:tensorflow:loss = 9.427017, step = 4500 (30.982 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2286\n",
            "INFO:tensorflow:loss = 9.153776, step = 4600 (30.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22263\n",
            "INFO:tensorflow:loss = 9.896345, step = 4700 (31.027 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22868\n",
            "INFO:tensorflow:loss = 8.990035, step = 4800 (30.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22238\n",
            "INFO:tensorflow:loss = 9.5339775, step = 4900 (31.030 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2271\n",
            "INFO:tensorflow:loss = 9.476618, step = 5000 (30.991 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22603\n",
            "INFO:tensorflow:loss = 9.033327, step = 5100 (30.998 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23101\n",
            "INFO:tensorflow:loss = 9.020405, step = 5200 (30.948 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22781\n",
            "INFO:tensorflow:loss = 9.333793, step = 5300 (30.978 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22956\n",
            "INFO:tensorflow:loss = 9.367719, step = 5400 (30.968 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22919\n",
            "INFO:tensorflow:loss = 9.564915, step = 5500 (30.964 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23044\n",
            "INFO:tensorflow:loss = 9.23323, step = 5600 (30.956 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22293\n",
            "INFO:tensorflow:loss = 8.987308, step = 5700 (31.029 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5751 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.55463\n",
            "INFO:tensorflow:loss = 9.483273, step = 5800 (39.144 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22389\n",
            "INFO:tensorflow:loss = 9.51622, step = 5900 (31.019 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21636\n",
            "INFO:tensorflow:loss = 9.234997, step = 6000 (31.091 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22993\n",
            "INFO:tensorflow:loss = 9.565839, step = 6100 (30.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20893\n",
            "INFO:tensorflow:loss = 9.254384, step = 6200 (31.159 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22195\n",
            "INFO:tensorflow:loss = 8.265037, step = 6300 (31.041 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21877\n",
            "INFO:tensorflow:loss = 9.354131, step = 6400 (31.068 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23494\n",
            "INFO:tensorflow:loss = 8.619445, step = 6500 (30.911 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21315\n",
            "INFO:tensorflow:loss = 9.826476, step = 6600 (31.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22481\n",
            "INFO:tensorflow:loss = 9.257522, step = 6700 (31.013 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21301\n",
            "INFO:tensorflow:loss = 9.502195, step = 6800 (31.122 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22699\n",
            "INFO:tensorflow:loss = 8.804132, step = 6900 (30.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21528\n",
            "INFO:tensorflow:loss = 9.729264, step = 7000 (31.099 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2245\n",
            "INFO:tensorflow:loss = 9.761623, step = 7100 (31.017 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20745\n",
            "INFO:tensorflow:loss = 9.5051155, step = 7200 (31.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22489\n",
            "INFO:tensorflow:loss = 10.176375, step = 7300 (31.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.21149\n",
            "INFO:tensorflow:loss = 9.102889, step = 7400 (31.143 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22926\n",
            "INFO:tensorflow:loss = 9.752222, step = 7500 (30.962 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20945\n",
            "INFO:tensorflow:loss = 8.520603, step = 7600 (31.168 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 7657 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 2.53514\n",
            "INFO:tensorflow:loss = 9.627242, step = 7700 (39.439 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22039\n",
            "INFO:tensorflow:loss = 9.220728, step = 7800 (31.052 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22572\n",
            "INFO:tensorflow:loss = 9.27743, step = 7900 (31.003 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22128\n",
            "INFO:tensorflow:loss = 9.4408455, step = 8000 (31.045 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22775\n",
            "INFO:tensorflow:loss = 9.147112, step = 8100 (30.976 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22658\n",
            "INFO:tensorflow:loss = 9.1642065, step = 8200 (30.995 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22709\n",
            "INFO:tensorflow:loss = 9.5191965, step = 8300 (30.985 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22229\n",
            "INFO:tensorflow:loss = 8.7669525, step = 8400 (31.035 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.23073\n",
            "INFO:tensorflow:loss = 9.832137, step = 8500 (30.954 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22329\n",
            "INFO:tensorflow:loss = 9.064125, step = 8600 (31.026 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22794\n",
            "INFO:tensorflow:loss = 8.996128, step = 8700 (30.977 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22054\n",
            "INFO:tensorflow:loss = 9.082951, step = 8800 (31.050 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.22685\n",
            "INFO:tensorflow:loss = 8.914135, step = 8900 (30.989 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2201\n",
            "INFO:tensorflow:loss = 9.682841, step = 9000 (31.054 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 9049 into /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 9.555036.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7f94d87c77f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "metadata": {
        "id": "MwRxkbtJ7pJy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predict"
      ]
    },
    {
      "metadata": {
        "id": "NDw2zHLx6SOy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = classifier_cnn.predict(input_fn = lambda: predict_input_fn(test_swallen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KbusAkeL8CV5",
        "colab_type": "code",
        "outputId": "4b380f4a-04a5-47c1-c384-4529c44b4fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for elem in predictions:\n",
        "  results.append(elem['class_id'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/Colab Notebooks/60k text classification/cnn_with_rnn/model.ckpt-9049\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ehEpGYdN8C4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "results = results[:-12]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jlgTseSI8Jvz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! touch '/content/submission_cnn_rnn.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sgby-LJh8E5i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/submission_cnn_rnn.csv', 'w') as file:\n",
        "  file.write('index' +',' + 'labels' + '\\n')\n",
        "  for index, label in zip(range(len(results)), results):\n",
        "    file.write(str(index) + ',' + str(label) + '\\n' if label!= 60416 else str(index) + ',' + str(-1) + '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1RHnDr2e8ZAx",
        "colab_type": "code",
        "outputId": "6969f7c2-5dec-46bc-9416-9f2b89b825a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "! KAGGLE_USERNAME='nikitamartynov' KAGGLE_KEY='3fabe7b3f96f3f0b04b23fd757efb93c' kaggle competitions submit -c 60k-classes-text-classification -f submission_cnn_rnn.csv -m \"pls, do not judge\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100% 506k/506k [00:08<00:00, 63.7kB/s]\n",
            "Successfully submitted to 60k Classes Text Classification"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2__07DC18dtE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}